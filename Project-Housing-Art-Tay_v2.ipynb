{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Kaggle Housing Price Prediction Challenge\"\n",
    "author: \"Art Tay\"\n",
    "format:\n",
    "  pdf:\n",
    "   documentclass: article\n",
    "   papersize: letter\n",
    "\n",
    "execute:\n",
    "  enabled: true\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "from sklearn_pandas import dataframe_mapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data\n",
    "train = pd.read_csv(\"data/train.csv\")\n",
    "test = pd.read_csv(\"data/test.csv\")\n",
    "#train.info()\n",
    "#test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generic Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts all object (string) columns to \n",
    "# be categorical.\n",
    "# @param: train - a pandas dataframe\n",
    "# Note: Technically unnecessary because pd.get_dummies will \n",
    "# dummy string, objects and category.\n",
    "def to_cat(train):\n",
    "    train[train.select_dtypes(['object']).columns] = (\n",
    "        train.select_dtypes(['object'])\n",
    "        .apply(lambda x: x.astype('category'))\n",
    "    )\n",
    "    return train\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Penalized Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code string columns as categorical\n",
    "train['MSSubClass'] = train['MSSubClass'].astype('category')\n",
    "\n",
    "train[train.select_dtypes(['object']).columns] = (\n",
    "    train.select_dtypes(['object'])\n",
    "    .apply(lambda x: x.astype('category'))\n",
    ")\n",
    "\n",
    "# Feature Engineering\n",
    "# NewGarage\n",
    "train['NewGarage'] = (\n",
    "    np.where(train['GarageYrBlt'].isnull(), 0, \n",
    "        np.where(train['GarageYrBlt'] > train['YearBuilt'], 1, 0))\n",
    ")\n",
    "\n",
    "# YearSinceRmdl\n",
    "train['YearSinceRmdl'] = 2016 - train['YearRemodAdd']\n",
    "\n",
    "# Rmdl\n",
    "train['Rmdl'] = np.where(train['YearBuilt'] < train['YearRemodAdd'], 1, 0)\n",
    "\n",
    "# TotalPorchArea\n",
    "train['TotalPorchArea'] = (\n",
    "    train['WoodDeckSF'] + train['OpenPorchSF'] + \n",
    "    train['EnclosedPorch'] + train['3SsnPorch'] + \n",
    "    train['ScreenPorch']\n",
    ")\n",
    "\n",
    "#PorchYes\n",
    "train['PorchYes'] = np.where(train['TotalPorchArea'] > 0, 1, 0)\n",
    "\n",
    "# TotalFinishedBsmt\n",
    "train['TotalFinishedBsmt'] = train['BsmtFinSF1'] + train['BsmtFinSF2']\n",
    "\n",
    "# PercentFinishedBsmt\n",
    "train['PercentFinishedBsmt'] = np.where(train['TotalBsmtSF'] > 0, \n",
    "    train['TotalFinishedBsmt'] / train['TotalBsmtSF'] * 100, 0)\n",
    "\n",
    "# TotalSqFt\n",
    "train['TotalSqFt'] = train['GrLivArea'] + train['TotalFinishedBsmt']\n",
    "\n",
    "# PercentLowQual\n",
    "train['PercentLowQual'] = train['LowQualFinSF'] * 100 / train['TotalSqFt']\n",
    "\n",
    "# IsNew\n",
    "train['IsNew'] = np.where(train['YrSold'] == train['YearRemodAdd'], 1, 0)\n",
    "\n",
    "# House_Age\n",
    "train['House_age'] = train['YrSold'] - train['YearRemodAdd']\n",
    "\n",
    "# NeighRich\n",
    "train['NeighRich'] = np.select(\n",
    "    condlist = [\n",
    "        train['Neighborhood'] == ('StoneBr' or 'NridgHt' or 'NoRidge'), \n",
    "        train['Neighborhood'] == ('MeadowV' or 'IDOTRR' or 'BrDale')\n",
    "    ], \n",
    "    choicelist = [2, 0],\n",
    "    default = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4 5]\n",
      "[0 1 2 3 4 5]\n",
      "[0 1 2 4 5 6]\n"
     ]
    }
   ],
   "source": [
    "def get_col(train, x): \n",
    "    return train[x].head()\n",
    "\n",
    "get_col(train, \"NeighRich\")\n",
    "\n",
    "# Converts a categorical column to be on an ordeal scale.\n",
    "# Scale was determined ad-hoc.\n",
    "# @param: train - a pandas dataframe\n",
    "# @param: col_name - a string name of the column to be converted\n",
    "def ord_scale_1(train, col_name):\n",
    "    ret = np.select(\n",
    "        condlist = [\n",
    "            train[col_name] == \"Ex\", \n",
    "            train[col_name] == \"Gd\", \n",
    "            train[col_name] == \"TA\", \n",
    "            train[col_name] == \"Fa\", \n",
    "            train[col_name] == \"Po\"\n",
    "        ], \n",
    "        choicelist = [5, 4, 3, 2, 1], \n",
    "        default = 0\n",
    "    )\n",
    "    return ret\n",
    "\n",
    "def ord_scale_2(train, col_name):\n",
    "    ret = np.select(\n",
    "        condlist = [\n",
    "            train[col_name] == \"GLQ\", \n",
    "            train[col_name] == \"ALQ\", \n",
    "            train[col_name] == \"BLQ\", \n",
    "            train[col_name] == \"REC\", \n",
    "            train[col_name] == \"LwQ\", \n",
    "            train[col_name] == \"Unf\", \n",
    "        ], \n",
    "        choicelist = [6, 5, 4, 3, 2, 1], \n",
    "        default = 0\n",
    "    )\n",
    "    return ret\n",
    "\n",
    "# Test\n",
    "print(np.unique(ord_scale_1(train, \"ExterCond\")))\n",
    "print(np.unique(ord_scale_1(train, \"GarageQual\")))\n",
    "print(np.unique(ord_scale_2(train, \"BsmtFinType2\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordinal Recoding\n",
    "train['LotShape'] = np.select(\n",
    "    condlist = [\n",
    "        train['LotShape'] == \"Reg\", \n",
    "        train['LotShape'] == \"IR1\", \n",
    "        train['LotShape'] == \"IR2\", \n",
    "        train['LotShape'] == \"IR3\" \n",
    "    ], \n",
    "    choicelist = [3, 2, 1, 0]\n",
    ")\n",
    "\n",
    "train['LandSlope'] = np.select(\n",
    "    condlist = [\n",
    "        train['LandSlope'] == \"Gtl\", \n",
    "        train['LandSlope'] == \"Mod\", \n",
    "        train['LandSlope'] == \"Sev\"\n",
    "    ], \n",
    "    choicelist = [2, 1, 0]\n",
    ")\n",
    "\n",
    "train['BsmtExposure'] = np.select(\n",
    "    condlist = [\n",
    "        train['BsmtExposure'] == \"Gd\", \n",
    "        train['BsmtExposure'] == \"Av\", \n",
    "        train['BsmtExposure'] == \"Mn\", \n",
    "        train['BsmtExposure'] == \"No\"\n",
    "    ], \n",
    "    choicelist = [4, 3, 2, 1], \n",
    "    default = 0\n",
    ")\n",
    "\n",
    "train['GarageFinish'] = np.select(\n",
    "    condlist = [\n",
    "        train['GarageFinish'] == \"Fin\", \n",
    "        train['GarageFinish'] == \"RFn\", \n",
    "        train['GarageFinish'] == \"Unf\", \n",
    "    ], \n",
    "    choicelist = [3, 2, 1], \n",
    "    default = 0\n",
    ")\n",
    "\n",
    "train['Functional'] = np.select(\n",
    "    condlist = [\n",
    "        train['Functional'] == \"Typ\", \n",
    "        train['Functional'] == \"Min1\", \n",
    "        train['Functional'] == \"Min2\", \n",
    "        train['Functional'] == \"Mod\", \n",
    "        train['Functional'] == \"Maj1\", \n",
    "        train['Functional'] == \"Maj2\", \n",
    "        train['Functional'] == \"Sev\", \n",
    "        train['Functional'] == \"Sal\" \n",
    "    ], \n",
    "    choicelist = [7, 6, 5, 4, 3, 2, 1, 0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop ID variable\n",
    "#train = train.drop('Id', axis = 1)\n",
    "\n",
    "#train_copy = train\n",
    "#print(train.shape)\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "# Create a dummy creation rule. \n",
    "dummy = OneHotEncoder(drop = 'first')\n",
    "\n",
    "# Get the names of all categorical columns to dummy \n",
    "dummy_col_names = train.select_dtypes('category').columns\n",
    "\n",
    "# Get the dummy value for all the columns\n",
    "dummy_col_values = dummy.fit_transform(train[dummy_col_names]).toarray()\n",
    "\n",
    "# Drop the original columns\n",
    "train = train.drop(dummy_col_names, axis = 1)\n",
    "\n",
    "## Add the dummy cols to the original dataframe\n",
    "train = train.join(pd.DataFrame(dummy_col_values, \n",
    "    columns = dummy.get_feature_names_out().tolist()))\n",
    "\n",
    "# Reserve dummy transform\n",
    "no_dummy_values = dummy.inverse_transform(dummy_col_values) \n",
    "train = train.drop(dummy.get_feature_names_out().tolist(), axis = 1)\n",
    "train = train.join(pd.DataFrame(no_dummy_values, columns = dummy_col_names))\n",
    "#print(train.shape)\n",
    "\n",
    "#print(train.head())\n",
    "#print(\"this is a seperator\")\n",
    "#print(train_copy.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['YearSinceRmdl', 'TotalFinishedBsmt', 'PercentLowQual', 'House_age']\n"
     ]
    }
   ],
   "source": [
    "# Extract response\n",
    "if 'SalePrice' in train:\n",
    "    response = train['SalePrice']\n",
    "    train = train.drop('SalePrice', axis = 1)\n",
    "else: \n",
    "    train = train\n",
    "\n",
    "# Dummies\n",
    "train = pd.get_dummies(train)\n",
    "\n",
    "# Center + Scale \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "train = pd.DataFrame(scaler.fit_transform(train), columns = train.columns)\n",
    "\n",
    "# knnImpute \n",
    "from sklearn.impute import KNNImputer\n",
    "imputer = KNNImputer(n_neighbors = 5)\n",
    "train = pd.DataFrame(imputer.fit_transform(train), columns = train.columns)\n",
    "\n",
    "# Reverse center + scale for other preprocessing methods.\n",
    "train = pd.DataFrame(scaler.inverse_transform(train), columns = train.columns)\n",
    "\n",
    "## NZV - remove all variable with less than 5% variance.\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "selector = VarianceThreshold(threshold = 0.05)\n",
    "train = train.loc[:, selector.fit(train).get_support()]\n",
    "\n",
    "# Corr\n",
    "def drop_high_cor(df, threshold = 0.9):\n",
    "    # Create correlation matrix\n",
    "    corr_matrix = df.corr().abs()\n",
    "\n",
    "    # Select upper triangle of correlation matrix\n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "\n",
    "    # Find features with correlation greater than 0.95\n",
    "    to_drop = [column for column in upper.columns if any(upper[column] > threshold)]\n",
    "\n",
    "    print(to_drop)\n",
    "\n",
    "    # Drop features \n",
    "    return df.drop(to_drop, axis=1)\n",
    "\n",
    "train = drop_high_cor(train, threshold = 0.9)\n",
    "\n",
    "# Splines\n",
    "from sklearn.preprocessing import SplineTransformer\n",
    "# Reverse dummy encoding\n",
    "\n",
    "def add_ns_3(train, degree = 3, knots = 5): \n",
    "    cols = train.select_dtypes(include = np.number).columns\n",
    "    spliner = SplineTransformer(degree = degree, n_knots = knots, include_bias = False)\n",
    "\n",
    "    for i in cols:\n",
    "        x = train[i].values.reshape(-1, 1)\n",
    "        new_col_names = [(i + \"_ns\" + str(j)) for j in range(1, degree + 1)]\n",
    "        spline = pd.DataFrame(spliner.fit_transform(x), columns = new_col_names)\n",
    "        train = train.join(spline)\n",
    "        train.drop(i, axis = 1)\n",
    "\n",
    "\n",
    "# Yeo-Johnson \n",
    "\n",
    "# Log Price\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import SplineTransformer\n",
    "degree, knots = 3, 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       LotArea\n",
      "1       LotArea\n",
      "2       LotArea\n",
      "3       LotArea\n",
      "4       LotArea\n",
      "         ...   \n",
      "1455    LotArea\n",
      "1456    LotArea\n",
      "1457    LotArea\n",
      "1458    LotArea\n",
      "1459    LotArea\n",
      "Length: 1460, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unit Test\n",
    "train = train.idxmax(axis = 1)\n",
    "print(train)\n",
    "train.isnull().sum().sum()\n",
    "#train['NeighRich'].unique()\n",
    "#train['SalePrice'].isnull().sum()\n",
    "\n",
    "#test.info()\n",
    "#if 'SalePrice' in train:\n",
    "    #test_69 = train.drop('SalePrice', axis = 1)\n",
    "#else: \n",
    "    #test_69 = train\n",
    "#print(test_69.equals(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neutral Network"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "2043299c89c8cd0b4d1a6f5cf4529bd58e6a4e0fe3181a25e0d328c821cdc5c5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
