{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Kaggle Housing Price Prediction Challenge\"\n",
    "author: \"Art Tay\"\n",
    "format:\n",
    "  pdf:\n",
    "   documentclass: article\n",
    "   papersize: letter\n",
    "\n",
    "execute:\n",
    "  enabled: true\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "# sklearn transformers\n",
    "from sklearn.preprocessing \\\n",
    "    import StandardScaler, SplineTransformer, PowerTransformer, OneHotEncoder\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.feature_selection import VarianceThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Id', 'MSSubClass', 'MSZoning', 'LotFrontage', 'LotArea', 'Street',\n",
       "       'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig',\n",
       "       'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType',\n",
       "       'HouseStyle', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd',\n",
       "       'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType',\n",
       "       'MasVnrArea', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual',\n",
       "       'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1',\n",
       "       'BsmtFinType2', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'Heating',\n",
       "       'HeatingQC', 'CentralAir', 'Electrical', '1stFlrSF', '2ndFlrSF',\n",
       "       'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath',\n",
       "       'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual',\n",
       "       'TotRmsAbvGrd', 'Functional', 'Fireplaces', 'FireplaceQu', 'GarageType',\n",
       "       'GarageYrBlt', 'GarageFinish', 'GarageCars', 'GarageArea', 'GarageQual',\n",
       "       'GarageCond', 'PavedDrive', 'WoodDeckSF', 'OpenPorchSF',\n",
       "       'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'PoolQC',\n",
       "       'Fence', 'MiscFeature', 'MiscVal', 'MoSold', 'YrSold', 'SaleType',\n",
       "       'SaleCondition', 'SalePrice'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in data\n",
    "train_raw = pd.read_csv(\"data/train.csv\")\n",
    "test_raw = pd.read_csv(\"data/test.csv\")\n",
    "train = train_raw\n",
    "train_raw.columns\n",
    "#test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generic Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts all object (string) columns to \n",
    "# be categorical.\n",
    "# @param: train - data in its raw form\n",
    "# @return: a pandas data frame with objects coded as categorical \n",
    "def to_cat(train):\n",
    "    train[train.select_dtypes(['object']).columns] = (\n",
    "        train.select_dtypes(['object'])\n",
    "        .apply(lambda x: x.astype('category'))\n",
    "    )\n",
    "    return train\n",
    "\n",
    "# Codes ad-hoc features to be categorical if they appear numeric\n",
    "# in the raw format. \n",
    "# @param: train - data in its raw form\n",
    "# @return: a pandas data frame with some columns marked as categorical.\n",
    "def some_num_to_cat(train): \n",
    "    train['MSSubClass'] = train['MSSubClass'].astype('category')\n",
    "    train['YearBuilt'] = train['YearBuilt'].astype('category')\n",
    "    train['YearRemodAdd'] = train['YearRemodAdd'].astype('category')\n",
    "    train['GarageYrBlt'] = train['GarageYrBlt'].astype('category')\n",
    "    train['MoSold'] = train['MoSold'].astype('category')\n",
    "    train['YrSold'] = train['YrSold'].astype('category')\n",
    "\n",
    "    return train\n",
    "\n",
    "# Engineering pre-spec features\n",
    "# @param: train - data in its raw form \n",
    "# @return: a pandas data frame with added features\n",
    "def feat_eng(train): \n",
    "    # Feature Engineering\n",
    "    # NewGarage\n",
    "    train['NewGarage'] = (\n",
    "        np.where(train['GarageYrBlt'].isnull(), 0, \n",
    "            np.where(train['GarageYrBlt'] > train['YearBuilt'], 1, 0))\n",
    "    )\n",
    "    train['NewGarage'] = train['NewGarage'].astype('category')\n",
    "\n",
    "    # YearSinceRmdl\n",
    "    train['YearSinceRmdl'] = 2016 - train['YearRemodAdd']\n",
    "\n",
    "    # Rmdl\n",
    "    train['Rmdl'] = np.where(\n",
    "            train['YearBuilt'] < train['YearRemodAdd'], 1, 0)\n",
    "    train['Rmdl'] = train['Rmdl'].astype('category')\n",
    "\n",
    "    # TotalPorchArea\n",
    "    train['TotalPorchArea'] = (\n",
    "        train['WoodDeckSF'] + train['OpenPorchSF'] + \n",
    "        train['EnclosedPorch'] + train['3SsnPorch'] + \n",
    "        train['ScreenPorch']\n",
    "    )\n",
    "\n",
    "    #PorchYes\n",
    "    train['PorchYes'] = np.where(train['TotalPorchArea'] > 0, 1, 0)\n",
    "    train['PorchYes'] = train['PorchYes'].astype('category')\n",
    "\n",
    "    # TotalFinishedBsmt\n",
    "    train['TotalFinishedBsmt'] = train['BsmtFinSF1'] + train['BsmtFinSF2']\n",
    "\n",
    "    # PercentFinishedBsmt\n",
    "    train['PercentFinishedBsmt'] = np.where(train['TotalBsmtSF'] > 0, \n",
    "        train['TotalFinishedBsmt'] / train['TotalBsmtSF'] * 100, 0)\n",
    "\n",
    "    # TotalSqFt\n",
    "    train['TotalSqFt'] = train['GrLivArea'] + train['TotalFinishedBsmt']\n",
    "\n",
    "    # PercentLowQual\n",
    "    train['PercentLowQual'] = train['LowQualFinSF'] * 100 / train['TotalSqFt']\n",
    "\n",
    "    # IsNew\n",
    "    train['IsNew'] = np.where(\n",
    "        train['YrSold'] == train['YearRemodAdd'], 1, 0)\n",
    "    train['IsNew'] = train['IsNew'].astype('category')\n",
    "\n",
    "    # House_Age\n",
    "    train['House_age'] = train['YrSold'] - train['YearRemodAdd']\n",
    "\n",
    "    # NeighRich\n",
    "    train['NeighRich'] = np.select(\n",
    "        condlist = [\n",
    "            train['Neighborhood'] == ('StoneBr' or 'NridgHt' or 'NoRidge'), \n",
    "            train['Neighborhood'] == ('MeadowV' or 'IDOTRR' or 'BrDale')\n",
    "        ], \n",
    "        choicelist = [2, 0],\n",
    "        default = 1\n",
    "    )\n",
    "    train['NeighRich'] = train['NeighRich'].astype('category')\n",
    "    \n",
    "    return train\n",
    "\n",
    "# A helper function that converts a column to an ordinal scale.\n",
    "# Scale was determined ad-hoc.\n",
    "# @param: train - data in its raw form \n",
    "# @param: col_name - a string name of the column to be converted\n",
    "def ord_scale_1(train, col_name):\n",
    "    ret = np.select(\n",
    "        condlist = [\n",
    "            train[col_name] == \"Ex\", \n",
    "            train[col_name] == \"Gd\", \n",
    "            train[col_name] == \"TA\", \n",
    "            train[col_name] == \"Fa\", \n",
    "            train[col_name] == \"Po\"\n",
    "        ], \n",
    "        choicelist = [5, 4, 3, 2, 1], \n",
    "        default = 0\n",
    "    )\n",
    "    return ret\n",
    "\n",
    "def ord_scale_2(train, col_name):\n",
    "    ret = np.select(\n",
    "        condlist = [\n",
    "            train[col_name] == \"GLQ\", \n",
    "            train[col_name] == \"ALQ\", \n",
    "            train[col_name] == \"BLQ\", \n",
    "            train[col_name] == \"REC\", \n",
    "            train[col_name] == \"LwQ\", \n",
    "            train[col_name] == \"Unf\", \n",
    "        ], \n",
    "        choicelist = [6, 5, 4, 3, 2, 1], \n",
    "        default = 0\n",
    "    )\n",
    "    return ret\n",
    "\n",
    "def ord_encode(train): \n",
    "    # Ordinal Scale 1\n",
    "    cols_scale_1 = ['ExterQual', 'ExterCond', 'HeatingQC', 'KitchenQual', \n",
    "                    'BsmtQual', 'BsmtCond', 'FireplaceQu', 'GarageQual', \n",
    "                    'GarageCond', 'PoolQC']\n",
    "    \n",
    "    for i in cols_scale_1:\n",
    "        train[i] = ord_scale_1(train, i)\n",
    "\n",
    "    # Ordinal Scale 2 \n",
    "    train['BsmtFinType1'] = ord_scale_2(train, 'BsmtFinType1')\n",
    "    train['BsmtFinType2'] = ord_scale_2(train, 'BsmtFinType2')\n",
    "\n",
    "    # Ad-hoc ordeal scales \n",
    "    train['LotShape'] = np.select(\n",
    "        condlist = [\n",
    "            train['LotShape'] == \"Reg\", \n",
    "            train['LotShape'] == \"IR1\", \n",
    "            train['LotShape'] == \"IR2\", \n",
    "            train['LotShape'] == \"IR3\" \n",
    "        ], \n",
    "        choicelist = [3, 2, 1, 0]\n",
    "    )\n",
    "\n",
    "    train['LandSlope'] = np.select(\n",
    "        condlist = [\n",
    "            train['LandSlope'] == \"Gtl\", \n",
    "            train['LandSlope'] == \"Mod\", \n",
    "            train['LandSlope'] == \"Sev\"\n",
    "        ], \n",
    "        choicelist = [2, 1, 0]\n",
    "    )\n",
    "\n",
    "    train['BsmtExposure'] = np.select(\n",
    "        condlist = [\n",
    "            train['BsmtExposure'] == \"Gd\", \n",
    "            train['BsmtExposure'] == \"Av\", \n",
    "            train['BsmtExposure'] == \"Mn\", \n",
    "            train['BsmtExposure'] == \"No\"\n",
    "        ], \n",
    "        choicelist = [4, 3, 2, 1], \n",
    "        default = 0\n",
    "    )\n",
    "\n",
    "    train['GarageFinish'] = np.select(\n",
    "        condlist = [\n",
    "            train['GarageFinish'] == \"Fin\", \n",
    "            train['GarageFinish'] == \"RFn\", \n",
    "            train['GarageFinish'] == \"Unf\", \n",
    "        ], \n",
    "        choicelist = [3, 2, 1], \n",
    "        default = 0\n",
    "    )\n",
    "\n",
    "    train['Functional'] = np.select(\n",
    "        condlist = [\n",
    "            train['Functional'] == \"Typ\", \n",
    "            train['Functional'] == \"Min1\", \n",
    "            train['Functional'] == \"Min2\", \n",
    "            train['Functional'] == \"Mod\", \n",
    "            train['Functional'] == \"Maj1\", \n",
    "            train['Functional'] == \"Maj2\", \n",
    "            train['Functional'] == \"Sev\", \n",
    "            train['Functional'] == \"Sal\" \n",
    "        ], \n",
    "        choicelist = [7, 6, 5, 4, 3, 2, 1, 0]\n",
    "    )\n",
    "\n",
    "    return train\n",
    "\n",
    "def knn_Impute(train, numeric_cols, cat_cols, neighbors = 5, \n",
    "                reverse_scale = True, reverse_dummy = True):\n",
    "    # Scale the numeric columns\n",
    "    scaler = StandardScaler()\n",
    "    scaled_values = scaler.fit_transform(train[numeric_cols])\n",
    "    train = train.drop(numeric_cols, axis = 1)\n",
    "    train = train.join(pd.DataFrame(scaled_values, columns = numeric_cols))\n",
    "\n",
    "    # Dummy the categorical columns \n",
    "    dummy = OneHotEncoder(drop = 'first')\n",
    "    dummy_values = dummy.fit_transform(train[cat_cols]).toarray()\n",
    "    dummy_names = dummy.get_feature_names_out().tolist()\n",
    "    train = train.drop(cat_cols, axis = 1)\n",
    "    train = train.join(pd.DataFrame(dummy_values, columns = dummy_names))\n",
    "\n",
    "    # Knn imputation\n",
    "    imputer = KNNImputer(n_neighbors = neighbors)\n",
    "    train = pd.DataFrame(imputer.fit_transform(train), columns = train.columns)\n",
    "\n",
    "    #print(train.head())\n",
    "\n",
    "    # Reverse scaling\n",
    "    if reverse_scale: \n",
    "        no_scale_values = scaler.inverse_transform(train[numeric_cols])\n",
    "        train = train.drop(numeric_cols, axis = 1)\n",
    "        train = train.join(pd.DataFrame(no_scale_values, columns = numeric_cols))\n",
    "\n",
    "    # Reverse dummies\n",
    "    if reverse_dummy: \n",
    "        no_dummy_values = dummy.inverse_transform(train[dummy_names]) \n",
    "        train = train.drop(dummy_names, axis = 1)\n",
    "        train = train.join(pd.DataFrame(no_dummy_values, columns = cat_cols))\n",
    "\n",
    "    # Reversal of dummy makes them objects again\n",
    "    return to_cat(train)\n",
    "\n",
    "def dummy_cols(train, cat_cols): \n",
    "    dummy = OneHotEncoder(drop = 'first')\n",
    "    dummy_values = dummy.fit_transform(train[cat_cols]).toarray()\n",
    "    dummy_names = dummy.get_feature_names_out().tolist()\n",
    "    train = train.drop(cat_cols, axis = 1)\n",
    "    train = train.join(pd.DataFrame(dummy_values, columns = dummy_names))\n",
    "\n",
    "    return train\n",
    "\n",
    "def drop_nzv(train, threshold = 0.05): \n",
    "    selector = VarianceThreshold(threshold = threshold)\n",
    "    train = train.loc[:, selector.fit(train).get_support()]\n",
    "\n",
    "    return train\n",
    "\n",
    "def yeo_johnson(train, numeric_cols, standardize = False):\n",
    "    yj = PowerTransformer(standardize = standardize)\n",
    "    yj_values = yj.fit_transform(train[numeric_cols])\n",
    "    train = train.drop(numeric_cols, axis = 1)\n",
    "    train = train.join(pd.DataFrame(yj_values, columns = numeric_cols))\n",
    "\n",
    "    return train\n",
    "\n",
    "def standardize(train, numeric_cols):\n",
    "    scaler = StandardScaler()\n",
    "    scaled_values = scaler.fit_transform(train[numeric_cols])\n",
    "    train = train.drop(numeric_cols, axis = 1)\n",
    "    train = train.join(pd.DataFrame(scaled_values, columns = numeric_cols))\n",
    "\n",
    "    return train\n",
    "\n",
    "def add_ns_3(train, cols, degree = 3, knots = 2): \n",
    "    spliner = SplineTransformer(degree = degree, n_knots = knots, include_bias = False)\n",
    "\n",
    "    for i in cols:\n",
    "        x = train[i].values.reshape(-1, 1)\n",
    "        new_col_names = [(i + \"_ns\" + str(j)) for j in range(1, degree + 1)]\n",
    "        spline = pd.DataFrame(spliner.fit_transform(x), columns = new_col_names)\n",
    "        train = train.join(spline)\n",
    "        train = train.drop(i, axis = 1)\n",
    "    \n",
    "    return train\n",
    "\n",
    "def drop_high_cor(df, threshold = 0.9):\n",
    "    # Create correlation matrix\n",
    "    corr_matrix = df.corr().abs()\n",
    "\n",
    "    # Select upper triangle of correlation matrix\n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "\n",
    "    # Find features with correlation greater than 0.95\n",
    "    to_drop = [column for column in upper.columns if any(upper[column] > threshold)]\n",
    "\n",
    "    # Drop features \n",
    "    return df.drop(to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Penalized Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user engineered features\n",
      "Encoded user specified variables as categorical\n",
      "Encoded user specified variables to be ordinal\n",
      "Imputed missing values using knn with k = 5\n",
      "Categorical columns were convert into n-1 binary dummy variables\n",
      "Yeo-Johnson Transformation of numeric columns\n",
      "Numeric columns scaled to mean 0 and unit variance\n",
      "Numeric features transformed into natural cubic splines\n",
      "Dropped columns with less than 0.01 variance\n",
      "Dropped 1 columns from every pair with >0.99 correlation\n",
      "Log transformation of SalePrice\n"
     ]
    }
   ],
   "source": [
    "verbose = True\n",
    "\n",
    "train = train_raw\n",
    "\n",
    "# Drop Id\n",
    "if 'Id' in train: \n",
    "    train_Id = train_raw['Id'] \n",
    "    train = train_raw.drop('Id', axis = 1)\n",
    "\n",
    "# Drop Response\n",
    "if 'SalePrice' in train: \n",
    "    train_rep = train_raw['SalePrice']\n",
    "    train = train.drop('SalePrice', axis = 1)\n",
    "\n",
    "# Add user features\n",
    "train = feat_eng(train)\n",
    "if verbose: print(\"Added user engineered features\")\n",
    "\n",
    "# Marks columns as categorical \n",
    "train = to_cat(train)\n",
    "train = some_num_to_cat(train)\n",
    "if verbose: print('Encoded user specified variables as categorical')\n",
    "\n",
    "# Ordinarily encodes select variables\n",
    "train = ord_encode(train)\n",
    "if verbose: print(\"Encoded user specified variables to be ordinal\")\n",
    "\n",
    "# Track which variables are numeric and categorical \n",
    "numeric_cols = train.select_dtypes(include = np.number).columns\n",
    "cat_cols = train.select_dtypes('category').columns\n",
    "\n",
    "# Imputes missing values\n",
    "train = knn_Impute(train, numeric_cols, cat_cols, reverse_dummy = True)\n",
    "if verbose: print(\"Imputed missing values using knn with k = 5\")\n",
    "\n",
    "# Create dummy variable\n",
    "train = dummy_cols(train, cat_cols)\n",
    "if verbose: print(\"Categorical columns were convert into n-1 binary dummy variables\")\n",
    "\n",
    "# Yeo-Johnson on Numerics\n",
    "train = yeo_johnson(train, numeric_cols)\n",
    "if verbose: print('Yeo-Johnson Transformation of numeric columns')\n",
    "\n",
    "# Standardized\n",
    "train = standardize(train, numeric_cols)\n",
    "if verbose: print('Numeric columns scaled to mean 0 and unit variance')\n",
    "\n",
    "# Splines\n",
    "train = add_ns_3(train, cols = numeric_cols)\n",
    "if verbose: print('Numeric features transformed into natural cubic splines')\n",
    "\n",
    "# Drop NZV\n",
    "train = drop_nzv(train, threshold = 0.01)\n",
    "if verbose: print(\"Dropped columns with less than 0.01 variance\")\n",
    "\n",
    "# Drop highly correlated columns\n",
    "train = drop_high_cor(train, threshold = 0.99)\n",
    "if verbose: print(\"Dropped 1 columns from every pair with >0.99 correlation\")\n",
    "\n",
    "# Add log Price back in \n",
    "train.insert(loc = 0, column = 'SalePrice', value = np.log(train_rep))\n",
    "if verbose: print(\"Log transformation of response\")\n",
    "\n",
    "# Add Ids back in\n",
    "train.insert(loc = 0, column = 'Id', value = train_Id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code string columns as categorical\n",
    "train['MSSubClass'] = train['MSSubClass'].astype('category')\n",
    "\n",
    "train[train.select_dtypes(['object']).columns] = (\n",
    "    train.select_dtypes(['object'])\n",
    "    .apply(lambda x: x.astype('category'))\n",
    ")\n",
    "\n",
    "# Feature Engineering\n",
    "# NewGarage\n",
    "train['NewGarage'] = (\n",
    "    np.where(train['GarageYrBlt'].isnull(), 0, \n",
    "        np.where(train['GarageYrBlt'] > train['YearBuilt'], 1, 0))\n",
    ")\n",
    "\n",
    "# YearSinceRmdl\n",
    "train['YearSinceRmdl'] = 2016 - train['YearRemodAdd']\n",
    "\n",
    "# Rmdl\n",
    "train['Rmdl'] = np.where(train['YearBuilt'] < train['YearRemodAdd'], 1, 0)\n",
    "\n",
    "# TotalPorchArea\n",
    "train['TotalPorchArea'] = (\n",
    "    train['WoodDeckSF'] + train['OpenPorchSF'] + \n",
    "    train['EnclosedPorch'] + train['3SsnPorch'] + \n",
    "    train['ScreenPorch']\n",
    ")\n",
    "\n",
    "#PorchYes\n",
    "train['PorchYes'] = np.where(train['TotalPorchArea'] > 0, 1, 0)\n",
    "\n",
    "# TotalFinishedBsmt\n",
    "train['TotalFinishedBsmt'] = train['BsmtFinSF1'] + train['BsmtFinSF2']\n",
    "\n",
    "# PercentFinishedBsmt\n",
    "train['PercentFinishedBsmt'] = np.where(train['TotalBsmtSF'] > 0, \n",
    "    train['TotalFinishedBsmt'] / train['TotalBsmtSF'] * 100, 0)\n",
    "\n",
    "# TotalSqFt\n",
    "train['TotalSqFt'] = train['GrLivArea'] + train['TotalFinishedBsmt']\n",
    "\n",
    "# PercentLowQual\n",
    "train['PercentLowQual'] = train['LowQualFinSF'] * 100 / train['TotalSqFt']\n",
    "\n",
    "# IsNew\n",
    "train['IsNew'] = np.where(train['YrSold'] == train['YearRemodAdd'], 1, 0)\n",
    "\n",
    "# House_Age\n",
    "train['House_age'] = train['YrSold'] - train['YearRemodAdd']\n",
    "\n",
    "# NeighRich\n",
    "train['NeighRich'] = np.select(\n",
    "    condlist = [\n",
    "        train['Neighborhood'] == ('StoneBr' or 'NridgHt' or 'NoRidge'), \n",
    "        train['Neighborhood'] == ('MeadowV' or 'IDOTRR' or 'BrDale')\n",
    "    ], \n",
    "    choicelist = [2, 0],\n",
    "    default = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4 5]\n",
      "[0 1 2 3 4 5]\n",
      "[0 1 2 4 5 6]\n"
     ]
    }
   ],
   "source": [
    "def get_col(train, x): \n",
    "    return train[x].head()\n",
    "\n",
    "get_col(train, \"NeighRich\")\n",
    "\n",
    "# Converts a categorical column to be on an ordeal scale.\n",
    "# Scale was determined ad-hoc.\n",
    "# @param: train - a pandas dataframe\n",
    "# @param: col_name - a string name of the column to be converted\n",
    "def ord_scale_1(train, col_name):\n",
    "    ret = np.select(\n",
    "        condlist = [\n",
    "            train[col_name] == \"Ex\", \n",
    "            train[col_name] == \"Gd\", \n",
    "            train[col_name] == \"TA\", \n",
    "            train[col_name] == \"Fa\", \n",
    "            train[col_name] == \"Po\"\n",
    "        ], \n",
    "        choicelist = [5, 4, 3, 2, 1], \n",
    "        default = 0\n",
    "    )\n",
    "    return ret\n",
    "\n",
    "def ord_scale_2(train, col_name):\n",
    "    ret = np.select(\n",
    "        condlist = [\n",
    "            train[col_name] == \"GLQ\", \n",
    "            train[col_name] == \"ALQ\", \n",
    "            train[col_name] == \"BLQ\", \n",
    "            train[col_name] == \"REC\", \n",
    "            train[col_name] == \"LwQ\", \n",
    "            train[col_name] == \"Unf\", \n",
    "        ], \n",
    "        choicelist = [6, 5, 4, 3, 2, 1], \n",
    "        default = 0\n",
    "    )\n",
    "    return ret\n",
    "\n",
    "# Test\n",
    "print(np.unique(ord_scale_1(train, \"ExterCond\")))\n",
    "print(np.unique(ord_scale_1(train, \"GarageQual\")))\n",
    "print(np.unique(ord_scale_2(train, \"BsmtFinType2\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordinal Recoding\n",
    "train['LotShape'] = np.select(\n",
    "    condlist = [\n",
    "        train['LotShape'] == \"Reg\", \n",
    "        train['LotShape'] == \"IR1\", \n",
    "        train['LotShape'] == \"IR2\", \n",
    "        train['LotShape'] == \"IR3\" \n",
    "    ], \n",
    "    choicelist = [3, 2, 1, 0]\n",
    ")\n",
    "\n",
    "train['LandSlope'] = np.select(\n",
    "    condlist = [\n",
    "        train['LandSlope'] == \"Gtl\", \n",
    "        train['LandSlope'] == \"Mod\", \n",
    "        train['LandSlope'] == \"Sev\"\n",
    "    ], \n",
    "    choicelist = [2, 1, 0]\n",
    ")\n",
    "\n",
    "train['BsmtExposure'] = np.select(\n",
    "    condlist = [\n",
    "        train['BsmtExposure'] == \"Gd\", \n",
    "        train['BsmtExposure'] == \"Av\", \n",
    "        train['BsmtExposure'] == \"Mn\", \n",
    "        train['BsmtExposure'] == \"No\"\n",
    "    ], \n",
    "    choicelist = [4, 3, 2, 1], \n",
    "    default = 0\n",
    ")\n",
    "\n",
    "train['GarageFinish'] = np.select(\n",
    "    condlist = [\n",
    "        train['GarageFinish'] == \"Fin\", \n",
    "        train['GarageFinish'] == \"RFn\", \n",
    "        train['GarageFinish'] == \"Unf\", \n",
    "    ], \n",
    "    choicelist = [3, 2, 1], \n",
    "    default = 0\n",
    ")\n",
    "\n",
    "train['Functional'] = np.select(\n",
    "    condlist = [\n",
    "        train['Functional'] == \"Typ\", \n",
    "        train['Functional'] == \"Min1\", \n",
    "        train['Functional'] == \"Min2\", \n",
    "        train['Functional'] == \"Mod\", \n",
    "        train['Functional'] == \"Maj1\", \n",
    "        train['Functional'] == \"Maj2\", \n",
    "        train['Functional'] == \"Sev\", \n",
    "        train['Functional'] == \"Sal\" \n",
    "    ], \n",
    "    choicelist = [7, 6, 5, 4, 3, 2, 1, 0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop ID variable\n",
    "#train = train.drop('Id', axis = 1)\n",
    "\n",
    "#train_copy = train\n",
    "#print(train.shape)\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "# Create a dummy creation rule. \n",
    "dummy = OneHotEncoder(drop = 'first')\n",
    "\n",
    "# Get the names of all categorical columns to dummy \n",
    "dummy_col_names = train.select_dtypes('category').columns\n",
    "\n",
    "# Get the dummy value for all the columns\n",
    "dummy_col_values = dummy.fit_transform(train[dummy_col_names]).toarray()\n",
    "\n",
    "# Drop the original columns\n",
    "train = train.drop(dummy_col_names, axis = 1)\n",
    "\n",
    "## Add the dummy cols to the original dataframe\n",
    "train = train.join(pd.DataFrame(dummy_col_values, \n",
    "    columns = dummy.get_feature_names_out().tolist()))\n",
    "\n",
    "# Reserve dummy transform\n",
    "no_dummy_values = dummy.inverse_transform(dummy_col_values) \n",
    "train = train.drop(dummy.get_feature_names_out().tolist(), axis = 1)\n",
    "train = train.join(pd.DataFrame(no_dummy_values, columns = dummy_col_names))\n",
    "#print(train.shape)\n",
    "\n",
    "#print(train.head())\n",
    "#print(\"this is a seperator\")\n",
    "#print(train_copy.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['YearSinceRmdl', 'TotalFinishedBsmt', 'PercentLowQual', 'House_age']\n"
     ]
    }
   ],
   "source": [
    "# Extract response\n",
    "if 'SalePrice' in train:\n",
    "    response = train['SalePrice']\n",
    "    train = train.drop('SalePrice', axis = 1)\n",
    "else: \n",
    "    train = train\n",
    "\n",
    "# Dummies\n",
    "train = pd.get_dummies(train)\n",
    "\n",
    "# Center + Scale \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "train = pd.DataFrame(scaler.fit_transform(train), columns = train.columns)\n",
    "\n",
    "# knnImpute \n",
    "from sklearn.impute import KNNImputer\n",
    "imputer = KNNImputer(n_neighbors = 5)\n",
    "train = pd.DataFrame(imputer.fit_transform(train), columns = train.columns)\n",
    "\n",
    "# Reverse center + scale for other preprocessing methods.\n",
    "train = pd.DataFrame(scaler.inverse_transform(train), columns = train.columns)\n",
    "\n",
    "## NZV - remove all variable with less than 5% variance.\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "selector = VarianceThreshold(threshold = 0.05)\n",
    "train = train.loc[:, selector.fit(train).get_support()]\n",
    "\n",
    "# Corr\n",
    "def drop_high_cor(df, threshold = 0.9):\n",
    "    # Create correlation matrix\n",
    "    corr_matrix = df.corr().abs()\n",
    "\n",
    "    # Select upper triangle of correlation matrix\n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "\n",
    "    # Find features with correlation greater than 0.95\n",
    "    to_drop = [column for column in upper.columns if any(upper[column] > threshold)]\n",
    "\n",
    "    print(to_drop)\n",
    "\n",
    "    # Drop features \n",
    "    return df.drop(to_drop, axis=1)\n",
    "\n",
    "train = drop_high_cor(train, threshold = 0.9)\n",
    "\n",
    "# Splines\n",
    "from sklearn.preprocessing import SplineTransformer\n",
    "# Reverse dummy encoding\n",
    "\n",
    "def add_ns_3(train, degree = 3, knots = 5): \n",
    "    cols = train.select_dtypes(include = np.number).columns\n",
    "    spliner = SplineTransformer(degree = degree, n_knots = knots, include_bias = False)\n",
    "\n",
    "    for i in cols:\n",
    "        x = train[i].values.reshape(-1, 1)\n",
    "        new_col_names = [(i + \"_ns\" + str(j)) for j in range(1, degree + 1)]\n",
    "        spline = pd.DataFrame(spliner.fit_transform(x), columns = new_col_names)\n",
    "        train = train.join(spline)\n",
    "        train.drop(i, axis = 1)\n",
    "\n",
    "\n",
    "# Yeo-Johnson \n",
    "\n",
    "# Log Price\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import SplineTransformer\n",
    "degree, knots = 3, 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       LotArea\n",
      "1       LotArea\n",
      "2       LotArea\n",
      "3       LotArea\n",
      "4       LotArea\n",
      "         ...   \n",
      "1455    LotArea\n",
      "1456    LotArea\n",
      "1457    LotArea\n",
      "1458    LotArea\n",
      "1459    LotArea\n",
      "Length: 1460, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unit Test\n",
    "train = train.idxmax(axis = 1)\n",
    "print(train)\n",
    "train.isnull().sum().sum()\n",
    "#train['NeighRich'].unique()\n",
    "#train['SalePrice'].isnull().sum()\n",
    "\n",
    "#test.info()\n",
    "#if 'SalePrice' in train:\n",
    "    #test_69 = train.drop('SalePrice', axis = 1)\n",
    "#else: \n",
    "    #test_69 = train\n",
    "#print(test_69.equals(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neutral Network"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "2043299c89c8cd0b4d1a6f5cf4529bd58e6a4e0fe3181a25e0d328c821cdc5c5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
